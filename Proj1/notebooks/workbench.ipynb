{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.3, 5.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "from metrics import TrainingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(2, 24, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(24, 49, kernel_size=3)\n",
    "        \n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(196, 128)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "        self.classifier = nn.Linear(10, 1)\n",
    "        \n",
    "        # Regularizers\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        \n",
    "        x = self.relu(self.fc1(x.flatten(start_dim=1)))\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        \n",
    "        x = self.relu(self.fc3(x.flatten(start_dim=1)))\n",
    "        \n",
    "        x = self.sigmoid(self.classifier(x))\n",
    "        \n",
    "        return x.squeeze(), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5207798a0d433e9be05c58c983b7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c5002ed6af4c509852ad7302fa23a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d21b5eb98d4f5e9ac891520cf00d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40b0894848b4140a5bf77bd83aa0216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnauddhaene/miniconda3/envs/ds/lib/python3.8/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-ggc7m97o/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, load):\n",
    "    \n",
    "    accuracy = 0.\n",
    "    counter = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for (input, target, _) in load:\n",
    "                output, _ = model(input)\n",
    "                \n",
    "                accuracy += (output >= 0.5) == target\n",
    "                counter += target.size(0)\n",
    "                \n",
    "    return (accuracy.sum() / counter).float().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 \tLoss 014.007 \tAccuracy 55.100\n",
      "Epoch 01 \tLoss 013.718 \tAccuracy 56.000\n",
      "Epoch 02 \tLoss 012.425 \tAccuracy 72.300\n",
      "Epoch 03 \tLoss 011.220 \tAccuracy 79.800\n",
      "Epoch 04 \tLoss 009.231 \tAccuracy 83.700\n",
      "Epoch 05 \tLoss 008.534 \tAccuracy 83.600\n",
      "Epoch 06 \tLoss 008.343 \tAccuracy 88.900\n",
      "Epoch 07 \tLoss 007.369 \tAccuracy 84.700\n",
      "Epoch 08 \tLoss 006.559 \tAccuracy 91.600\n",
      "Epoch 09 \tLoss 005.733 \tAccuracy 91.400\n",
      "Epoch 10 \tLoss 005.106 \tAccuracy 93.200\n",
      "Epoch 11 \tLoss 003.617 \tAccuracy 92.600\n",
      "Epoch 12 \tLoss 004.558 \tAccuracy 93.400\n",
      "Epoch 13 \tLoss 003.086 \tAccuracy 94.500\n",
      "Epoch 14 \tLoss 002.869 \tAccuracy 94.700\n",
      "Epoch 15 \tLoss 003.410 \tAccuracy 95.200\n",
      "Epoch 16 \tLoss 002.988 \tAccuracy 95.900\n",
      "Epoch 17 \tLoss 002.518 \tAccuracy 97.100\n",
      "Epoch 18 \tLoss 002.114 \tAccuracy 97.900\n",
      "Epoch 19 \tLoss 001.612 \tAccuracy 97.900\n",
      "Epoch 20 \tLoss 002.555 \tAccuracy 97.100\n",
      "Epoch 21 \tLoss 001.763 \tAccuracy 97.700\n",
      "Epoch 22 \tLoss 001.941 \tAccuracy 93.600\n",
      "Epoch 23 \tLoss 002.417 \tAccuracy 96.900\n",
      "Epoch 24 \tLoss 001.228 \tAccuracy 98.600\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "eta = 1e-2\n",
    "epochs = 25\n",
    "decay = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=eta, weight_decay=decay)\n",
    "\n",
    "metrics = TrainingMetrics()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    acc_loss = 0.\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for input, target, classes in train_loader:\n",
    "        \n",
    "        output, aux = model(input)\n",
    "        loss = criterion(output, target.float())\n",
    "        \n",
    "        acc_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    metrics.add_entry(epoch, acc_loss, accuracy(model, train_loader))\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04.555\n"
     ]
    }
   ],
   "source": [
    "print(f\"{4.555:06.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0d7cb636eb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtraining_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "training_stats = pd.DataFrame.from_dict(stats, orient='index')\n",
    "training_stats['epoch'] = training_stats.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_loss = sns.lineplot(data=training_stats, x=\"epoch\", y=\"loss\", label='loss')\n",
    "\n",
    "ax_acc = ax_loss.twinx()\n",
    "\n",
    "sns.lineplot(data=training_stats, x=\"epoch\", y=\"accuracy\", label='accuracy', ax=ax_acc, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
